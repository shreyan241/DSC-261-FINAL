{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Variable1                  Variable2  Correlation\n",
      "1030          numbUrban numeric         population numeric     0.999033\n",
      "10           population numeric          numbUrban numeric     0.999033\n",
      "5929       PctRecImmig8 numeric      PctRecImmig10 numeric     0.994987\n",
      "6031      PctRecImmig10 numeric       PctRecImmig8 numeric     0.994987\n",
      "5825       PctRecImmig5 numeric       PctRecImmig8 numeric     0.993569\n",
      "5927       PctRecImmig8 numeric       PctRecImmig5 numeric     0.993569\n",
      "8215       OwnOccMedVal numeric     OwnOccLowQuart numeric     0.991562\n",
      "8113     OwnOccLowQuart numeric       OwnOccMedVal numeric     0.991562\n",
      "5721     PctRecentImmig numeric       PctRecImmig5 numeric     0.990420\n",
      "5823       PctRecImmig5 numeric     PctRecentImmig numeric     0.990420\n",
      "26           population numeric        NumUnderPov numeric     0.990041\n",
      "2678        NumUnderPov numeric         population numeric     0.990041\n",
      "2688        NumUnderPov numeric          numbUrban numeric     0.988138\n",
      "1056          numbUrban numeric        NumUnderPov numeric     0.988138\n",
      "8635          RentHighQ numeric   MedOwnCostPctInc numeric     0.988117\n",
      "8941   MedOwnCostPctInc numeric          RentHighQ numeric     0.988117\n",
      "6345    PctLargHouseFam numeric  PctLargHouseOccup numeric     0.986414\n",
      "6447  PctLargHouseOccup numeric    PctLargHouseFam numeric     0.986414\n",
      "4471        PctKids2Par numeric         PctFam2Par numeric     0.985901\n",
      "4369         PctFam2Par numeric        PctKids2Par numeric     0.985901\n",
      "8319      OwnOccHiQuart numeric       OwnOccMedVal numeric     0.984895\n",
      "8217       OwnOccMedVal numeric      OwnOccHiQuart numeric     0.984895\n",
      "6030      PctRecImmig10 numeric       PctRecImmig5 numeric     0.984701\n",
      "5826       PctRecImmig5 numeric      PctRecImmig10 numeric     0.984701\n",
      "2726        NumUnderPov numeric           NumIlleg numeric     0.983812\n",
      "4970           NumIlleg numeric        NumUnderPov numeric     0.983812\n",
      "4057       FemalePctDiv numeric        TotalPctDiv numeric     0.983225\n",
      "4159        TotalPctDiv numeric       FemalePctDiv numeric     0.983225\n",
      "7482      PctHousOwnOcc numeric    PctPersOwnOccup numeric     0.981770\n",
      "6870    PctPersOwnOccup numeric      PctHousOwnOcc numeric     0.981770\n",
      "8633          RentHighQ numeric            MedRent numeric     0.979808\n",
      "8735            MedRent numeric          RentHighQ numeric     0.979808\n",
      "5722     PctRecentImmig numeric       PctRecImmig8 numeric     0.979418\n",
      "5926       PctRecImmig8 numeric     PctRecentImmig numeric     0.979418\n",
      "1255          medIncome numeric          medFamInc numeric     0.979045\n",
      "1969          medFamInc numeric          medIncome numeric     0.979045\n",
      "8738            MedRent numeric   MedOwnCostPctInc numeric     0.977454\n",
      "8942   MedOwnCostPctInc numeric            MedRent numeric     0.977454\n",
      "3851     MalePctDivorce numeric        TotalPctDiv numeric     0.975153\n",
      "4157        TotalPctDiv numeric     MalePctDivorce numeric     0.975153\n",
      "2183        whitePerCap numeric          perCapInc numeric     0.974818\n",
      "2081          perCapInc numeric        whitePerCap numeric     0.974818\n",
      "48           population numeric           NumIlleg numeric     0.973005\n",
      "4944           NumIlleg numeric         population numeric     0.973005\n",
      "4954           NumIlleg numeric          numbUrban numeric     0.971168\n",
      "1078          numbUrban numeric           NumIlleg numeric     0.971168\n",
      "5723     PctRecentImmig numeric      PctRecImmig10 numeric     0.966948\n",
      "6029      PctRecImmig10 numeric     PctRecentImmig numeric     0.966948\n",
      "8114     OwnOccLowQuart numeric      OwnOccHiQuart numeric     0.964112\n",
      "8318      OwnOccHiQuart numeric     OwnOccLowQuart numeric     0.964112\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data/cc_forest_train.csv')\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Create a DataFrame from the correlation matrix, stack it, and reset its index\n",
    "corr_stack = corr_matrix.stack().reset_index()\n",
    "\n",
    "# Name the columns for clarity\n",
    "corr_stack.columns = ['Variable1', 'Variable2', 'Correlation']\n",
    "\n",
    "# Remove self-correlation cases (where the two variables are the same)\n",
    "corr_stack_filtered = corr_stack[corr_stack['Variable1'] != corr_stack['Variable2']]\n",
    "\n",
    "# Sort by the absolute values of correlation to get both high positive and high negative correlations\n",
    "# Apply abs() only to the 'Correlation' column\n",
    "corr_stack_sorted = corr_stack_filtered.copy()\n",
    "corr_stack_sorted['Correlation'] = corr_stack_sorted['Correlation'].abs()\n",
    "corr_stack_sorted = corr_stack_sorted.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# Optional: drop duplicates to avoid reverse pairs (e.g., A-B and B-A) showing up\n",
    "# This step keeps the first occurrence of the reversed pairs based on the sorted values\n",
    "corr_stack_sorted = corr_stack_sorted.drop_duplicates(subset=['Variable1', 'Variable2'], keep='first')\n",
    "\n",
    "# Get the top N pairs with the highest correlation\n",
    "N = 50\n",
    "top_n_corr = corr_stack_sorted.head(N)\n",
    "\n",
    "print(top_n_corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Variable1          Variable2  Correlation\n",
      "61  c_charge_degree_F  c_charge_degree_M     0.667061\n",
      "71  c_charge_degree_M  c_charge_degree_F     0.667061\n",
      "95           sex_Male         sex_Female     0.625900\n",
      "85         sex_Female           sex_Male     0.625900\n",
      "27     two_year_recid  c_charge_degree_F     0.491191\n",
      "57  c_charge_degree_F     two_year_recid     0.491191\n",
      "28     two_year_recid  c_charge_degree_M     0.465922\n",
      "68  c_charge_degree_M     two_year_recid     0.465922\n",
      "62  c_charge_degree_F         sex_Female     0.385483\n",
      "82         sex_Female  c_charge_degree_F     0.385483\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Data/compas_CTGAN.csv')\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Create a DataFrame from the correlation matrix, stack it, and reset its index\n",
    "corr_stack = corr_matrix.stack().reset_index()\n",
    "\n",
    "# Name the columns for clarity\n",
    "corr_stack.columns = ['Variable1', 'Variable2', 'Correlation']\n",
    "\n",
    "# Remove self-correlation cases (where the two variables are the same)\n",
    "corr_stack_filtered = corr_stack[corr_stack['Variable1'] != corr_stack['Variable2']]\n",
    "\n",
    "# Sort by the absolute values of correlation to get both high positive and high negative correlations\n",
    "# Apply abs() only to the 'Correlation' column\n",
    "corr_stack_sorted = corr_stack_filtered.copy()\n",
    "corr_stack_sorted['Correlation'] = corr_stack_sorted['Correlation'].abs()\n",
    "corr_stack_sorted = corr_stack_sorted.sort_values(by='Correlation', ascending=False)\n",
    "\n",
    "# Optional: drop duplicates to avoid reverse pairs (e.g., A-B and B-A) showing up\n",
    "# This step keeps the first occurrence of the reversed pairs based on the sorted values\n",
    "corr_stack_sorted = corr_stack_sorted.drop_duplicates(subset=['Variable1', 'Variable2'], keep='first')\n",
    "\n",
    "# Get the top N pairs with the highest correlation\n",
    "N = 10\n",
    "top_n_corr = corr_stack_sorted.head(N)\n",
    "\n",
    "print(top_n_corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'statsmodels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstatsmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutliers_influence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variance_inflation_factor\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Assuming 'df' is your DataFrame and it contains only numeric predictors\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Function to calculate VIF for each feature\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_vif\u001b[39m(dataframe):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# Adding a constant column for intercept\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'statsmodels'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Assuming 'df' is your DataFrame and it contains only numeric predictors\n",
    "\n",
    "# Function to calculate VIF for each feature\n",
    "def calculate_vif(dataframe):\n",
    "    # Adding a constant column for intercept\n",
    "    X = dataframe.copy()\n",
    "    X['Intercept'] = 1\n",
    "    \n",
    "    # Calculating VIF for each feature\n",
    "    vifs = pd.DataFrame()\n",
    "    vifs[\"Variable\"] = X.columns\n",
    "    vifs[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    \n",
    "    # Removing the row for the intercept\n",
    "    vifs = vifs[vifs[\"Variable\"] != \"Intercept\"]\n",
    "    \n",
    "    return vifs\n",
    "\n",
    "# Calculate VIF\n",
    "vif_data = calculate_vif(df)\n",
    "\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.1-cp310-cp310-win_amd64.whl (9.8 MB)\n",
      "     ---------------------------------------- 9.8/9.8 MB 24.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2,>=1.22.3 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (1.23.3)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (1.9.1)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (1.5.0)\n",
      "Collecting patsy>=0.5.4\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "     -------------------------------------- 233.9/233.9 KB 7.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=21.3->statsmodels) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2022.4)\n",
      "Requirement already satisfied: six in c:\\users\\shash\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.6 statsmodels-0.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\shash\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
